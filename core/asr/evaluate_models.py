"""
Script Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh: So sÃ¡nh Whisper vs PhoWhisper
TÃ­nh WER (Word Error Rate) vÃ  CER (Character Error Rate)
"""
import os
import json
import torch
from pathlib import Path
from typing import Dict, List, Tuple
# Ensure FFmpeg configured before importing librosa (best-effort)
try:
    from core.audio.ffmpeg_setup import ensure_ffmpeg
    ensure_ffmpeg(silent=True)
except Exception:
    pass
import librosa
import soundfile as sf
import tempfile
from core.audio.audio_processor import _make_safe_temp_copy

# Import models
# Note: Cáº§n import trá»±c tiáº¿p whisper vÃ  transformers vÃ¬ khÃ´ng cÃ³ streamlit context
try:
    import whisper
    from transformers import pipeline
    import torch
except ImportError as e:
    print(f"Lá»—i import: {e}")
    print("Vui lÃ²ng Ä‘áº£m báº£o Ä‘Ã£ cÃ i Ä‘áº·t táº¥t cáº£ dependencies")
    exit(1)

from jiwer import wer, cer
import pandas as pd

def load_reference_texts(test_dir: str) -> Dict[str, str]:
    """
    Load reference texts tá»« file .txt trong thÆ° má»¥c test
    
    Format: má»—i audio file cÃ³ file .txt tÆ°Æ¡ng á»©ng vá»›i cÃ¹ng tÃªn
    VÃ­ dá»¥: audio1.wav -> audio1.txt
    
    Args:
        test_dir: ÄÆ°á»ng dáº«n thÆ° má»¥c chá»©a test files
    
    Returns:
        Dict: {audio_filename: reference_text}
    """
    references = {}
    test_path = Path(test_dir)
    
    if not test_path.exists():
        print(f"âš ï¸ ThÆ° má»¥c {test_dir} khÃ´ng tá»“n táº¡i. Táº¡o thÆ° má»¥c má»›i...")
        test_path.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ ÄÃ£ táº¡o thÆ° má»¥c {test_dir}")
        print("ğŸ’¡ Vui lÃ²ng thÃªm audio files (.wav, .mp3) vÃ  file reference text (.txt) tÆ°Æ¡ng á»©ng")
        return references
    
    # TÃ¬m táº¥t cáº£ audio files
    audio_extensions = ['.wav', '.mp3', '.flac', '.m4a', '.ogg']
    audio_files = []
    for ext in audio_extensions:
        audio_files.extend(list(test_path.glob(f'*{ext}')))
    
    # Load reference texts
    for audio_file in audio_files:
        txt_file = audio_file.with_suffix('.txt')
        if txt_file.exists():
            with open(txt_file, 'r', encoding='utf-8') as f:
                references[audio_file.name] = f.read().strip()
        else:
            print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file reference cho {audio_file.name}")
    
    return references

def evaluate_model_whisper(audio_path: str, model_size: str = "large") -> str:
    """
    Transcribe audio vá»›i Whisper
    
    Args:
        audio_path: ÄÆ°á»ng dáº«n file audio
        model_size: KÃ­ch thÆ°á»›c model Whisper
    
    Returns:
        str: Transcribed text
    """
    # Preflight checks to help diagnose WinError 2 (file not found) issues
    try:
        if not os.path.exists(audio_path):
            # Try creating a safe temp copy to avoid problems with odd filenames
            try:
                temp_copy = _make_safe_temp_copy(audio_path)
                audio_path = temp_copy
            except Exception as e:
                print(f"âŒ Audio path not found and could not create safe copy: {e}")
                return ""

        device = "cuda" if torch.cuda.is_available() else "cpu"
        model = whisper.load_model(model_size, device=device)

        result = model.transcribe(
            audio_path,
            language="vi",
            task="transcribe",
            fp16=False
        )

        if result:
            return result.get("text", "")
        return ""
    except Exception as e:
        print(f"âŒ Lá»—i khi transcribe vá»›i Whisper: {e}")
        return ""

def evaluate_model_phowhisper(audio_path: str, model_size: str = "medium") -> str:
    """
    Transcribe audio vá»›i PhoWhisper
    
    Args:
        audio_path: ÄÆ°á»ng dáº«n file audio
        model_size: KÃ­ch thÆ°á»›c model PhoWhisper
    
    Returns:
        str: Transcribed text
    """
    # Preflight checks to help diagnose WinError 2 (file not found) issues
    try:
        if not os.path.exists(audio_path):
            # Try creating a safe temp copy to avoid problems with odd filenames
            try:
                temp_copy = _make_safe_temp_copy(audio_path)
                audio_path = temp_copy
            except Exception as e:
                print(f"âŒ Audio path not found and could not create safe copy: {e}")
                return ""

        device = 0 if torch.cuda.is_available() else -1
        model_name = f"vinai/PhoWhisper-{model_size}"

        transcriber = pipeline(
            "automatic-speech-recognition",
            model=model_name,
            device=device
        )

        result = transcriber(audio_path, return_timestamps=True)

        if result:
            return result.get("text", "")
        return ""
    except Exception as e:
        print(f"âŒ Lá»—i khi transcribe vá»›i PhoWhisper: {e}")
        return ""

def run_evaluation(
    test_dir: str = "test_audio",
    whisper_model: str = "large",
    phowhisper_model: str = "medium",
    output_file: str = "docs/model_comparison.md"
) -> Dict:
    """
    Cháº¡y Ä‘Ã¡nh giÃ¡ so sÃ¡nh Whisper vs PhoWhisper
    
    Args:
        test_dir: ThÆ° má»¥c chá»©a test audio files
        whisper_model: Model Whisper Ä‘á»ƒ test
        phowhisper_model: Model PhoWhisper Ä‘á»ƒ test
        output_file: File output Ä‘á»ƒ lÆ°u káº¿t quáº£
    
    Returns:
        Dict: Káº¿t quáº£ Ä‘Ã¡nh giÃ¡
    """
    print("ğŸš€ Báº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh...")
    print(f"ğŸ“ ThÆ° má»¥c test: {test_dir}")
    print(f"ğŸ” Whisper model: {whisper_model}")
    print(f"ğŸ” PhoWhisper model: {phowhisper_model}")
    print("-" * 60)
    
    # Load reference texts
    references = load_reference_texts(test_dir)
    
    if not references:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y reference texts. Vui lÃ²ng thÃªm audio files vÃ  file .txt tÆ°Æ¡ng á»©ng.")
        return {}
    
    print(f"âœ… TÃ¬m tháº¥y {len(references)} file test\n")
    
    # Káº¿t quáº£
    results = []
    test_path = Path(test_dir)
    
    # Device info
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    for i, (audio_name, reference) in enumerate(references.items(), 1):
        audio_path = test_path / audio_name
        print(f"[{i}/{len(references)}] Äang xá»­ lÃ½ {audio_name}...")
        
        # Transcribe vá»›i Whisper
        print("  ğŸ”„ Transcribing vá»›i Whisper...")
        whisper_text = evaluate_model_whisper(str(audio_path), whisper_model)
        
        # Transcribe vá»›i PhoWhisper
        print("  ğŸ”„ Transcribing vá»›i PhoWhisper...")
        phowhisper_text = evaluate_model_phowhisper(str(audio_path), phowhisper_model)
        
        # TÃ­nh WER vÃ  CER
        whisper_wer = wer(reference, whisper_text) if whisper_text else 1.0
        whisper_cer = cer(reference, whisper_text) if whisper_text else 1.0
        
        phowhisper_wer = wer(reference, phowhisper_text) if phowhisper_text else 1.0
        phowhisper_cer = cer(reference, phowhisper_text) if phowhisper_text else 1.0
        
        results.append({
            'file': audio_name,
            'whisper_text': whisper_text,
            'phowhisper_text': phowhisper_text,
            'reference': reference,
            'whisper_wer': whisper_wer,
            'whisper_cer': whisper_cer,
            'phowhisper_wer': phowhisper_wer,
            'phowhisper_cer': phowhisper_cer
        })
        
        print(f"  âœ… Whisper - WER: {whisper_wer:.4f}, CER: {whisper_cer:.4f}")
        print(f"  âœ… PhoWhisper - WER: {phowhisper_wer:.4f}, CER: {phowhisper_cer:.4f}\n")
    
    # TÃ­nh thá»‘ng kÃª tá»•ng há»£p
    df = pd.DataFrame(results)
    
    summary = {
        'whisper_mean_wer': df['whisper_wer'].mean(),
        'whisper_std_wer': df['whisper_wer'].std(),
        'whisper_mean_cer': df['whisper_cer'].mean(),
        'whisper_std_cer': df['whisper_cer'].std(),
        'phowhisper_mean_wer': df['phowhisper_wer'].mean(),
        'phowhisper_std_wer': df['phowhisper_wer'].std(),
        'phowhisper_mean_cer': df['phowhisper_cer'].mean(),
        'phowhisper_std_cer': df['phowhisper_cer'].std(),
        'num_files': len(results),
        'device': device,
        'whisper_model': whisper_model,
        'phowhisper_model': phowhisper_model
    }
    
    # Táº¡o bÃ¡o cÃ¡o markdown
    create_report(results, summary, output_file)
    
    print("=" * 60)
    print("ğŸ“Š Káº¾T QUáº¢ Tá»”NG Há»¢P")
    print("=" * 60)
    print(f"Whisper-{whisper_model}:")
    print(f"  WER: {summary['whisper_mean_wer']:.4f} Â± {summary['whisper_std_wer']:.4f}")
    print(f"  CER: {summary['whisper_mean_cer']:.4f} Â± {summary['whisper_std_cer']:.4f}")
    print(f"\nPhoWhisper-{phowhisper_model}:")
    print(f"  WER: {summary['phowhisper_mean_wer']:.4f} Â± {summary['phowhisper_std_wer']:.4f}")
    print(f"  CER: {summary['phowhisper_mean_cer']:.4f} Â± {summary['phowhisper_std_cer']:.4f}")
    print(f"\nğŸ“„ BÃ¡o cÃ¡o chi tiáº¿t Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {output_file}")
    
    return {
        'results': results,
        'summary': summary
    }

def create_report(results: List[Dict], summary: Dict, output_file: str):
    """
    Táº¡o bÃ¡o cÃ¡o markdown
    
    Args:
        results: Danh sÃ¡ch káº¿t quáº£ tá»«ng file
        summary: Thá»‘ng kÃª tá»•ng há»£p
        output_file: ÄÆ°á»ng dáº«n file output
    """
    # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# So sÃ¡nh Whisper vs PhoWhisper\n\n")
        f.write("## ThÃ´ng tin Ä‘Ã¡nh giÃ¡\n\n")
        f.write(f"- **Sá»‘ file test**: {summary['num_files']}\n")
        f.write(f"- **Device**: {summary['device']}\n")
        f.write(f"- **Whisper model**: {summary['whisper_model']}\n")
        f.write(f"- **PhoWhisper model**: {summary['phowhisper_model']}\n\n")
        
        f.write("## Káº¿t quáº£ tá»•ng há»£p\n\n")
        f.write("| Model | WER (Mean Â± Std) | CER (Mean Â± Std) |\n")
        f.write("|-------|------------------|------------------|\n")
        f.write(f"| Whisper-{summary['whisper_model']} | "
                f"{summary['whisper_mean_wer']:.4f} Â± {summary['whisper_std_wer']:.4f} | "
                f"{summary['whisper_mean_cer']:.4f} Â± {summary['whisper_std_cer']:.4f} |\n")
        f.write(f"| PhoWhisper-{summary['phowhisper_model']} | "
                f"{summary['phowhisper_mean_wer']:.4f} Â± {summary['phowhisper_std_wer']:.4f} | "
                f"{summary['phowhisper_mean_cer']:.4f} Â± {summary['phowhisper_std_cer']:.4f} |\n\n")
        
        f.write("## Káº¿t quáº£ chi tiáº¿t tá»«ng file\n\n")
        f.write("| File | Whisper WER | Whisper CER | PhoWhisper WER | PhoWhisper CER |\n")
        f.write("|------|-------------|-------------|----------------|----------------|\n")
        
        for r in results:
            f.write(f"| {r['file']} | {r['whisper_wer']:.4f} | {r['whisper_cer']:.4f} | "
                   f"{r['phowhisper_wer']:.4f} | {r['phowhisper_cer']:.4f} |\n")
        
        f.write("\n## Káº¿t luáº­n\n\n")
        if summary['phowhisper_mean_wer'] < summary['whisper_mean_wer']:
            f.write("âœ… **PhoWhisper cÃ³ WER tháº¥p hÆ¡n Whisper**, cho tháº¥y Ä‘á»™ chÃ­nh xÃ¡c tá»‘t hÆ¡n cho tiáº¿ng Viá»‡t.\n\n")
        else:
            f.write("âš ï¸ **Whisper cÃ³ WER tháº¥p hÆ¡n PhoWhisper** trong test nÃ y. CÃ³ thá»ƒ cáº§n thÃªm test cases.\n\n")
        
        f.write("### Khuyáº¿n nghá»‹\n\n")
        f.write("- Sá»­ dá»¥ng **PhoWhisper** cho audio tiáº¿ng Viá»‡t Ä‘á»ƒ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c tá»‘t nháº¥t\n")
        f.write("- Sá»­ dá»¥ng **Whisper** náº¿u cáº§n há»— trá»£ Ä‘a ngÃ´n ngá»¯\n")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng Whisper vs PhoWhisper")
    parser.add_argument("--test_dir", type=str, default="test_audio",
                       help="ThÆ° má»¥c chá»©a test audio files (default: test_audio)")
    parser.add_argument("--whisper_model", type=str, default="large",
                       choices=["tiny", "base", "small", "medium", "large"],
                       help="Model Whisper Ä‘á»ƒ test (default: large)")
    parser.add_argument("--phowhisper_model", type=str, default="medium",
                       choices=["small", "medium", "base"],
                       help="Model PhoWhisper Ä‘á»ƒ test (default: medium)")
    parser.add_argument("--output", type=str, default="docs/model_comparison.md",
                       help="File output (default: docs/model_comparison.md)")
    
    args = parser.parse_args()
    
    run_evaluation(
        test_dir=args.test_dir,
        whisper_model=args.whisper_model,
        phowhisper_model=args.phowhisper_model,
        output_file=args.output
    )

