"""
Module transcription s·ª≠ d·ª•ng Whisper
"""
import os
import sys
import whisper
import torch
import streamlit as st
from typing import Optional, Dict, List
import numpy as np
import time
from core.audio.audio_processor import _make_safe_temp_copy

def check_python_version():
    """
    Ki·ªÉm tra Python version v√† c·∫£nh b√°o n·∫øu kh√¥ng ph√π h·ª£p v·ªõi Streamlit Cloud
    
    Returns:
        Tuple (is_valid: bool, warning_message: Optional[str])
    """
    version = sys.version_info
    if version.major == 3 and 9 <= version.minor <= 10:
        return True, None
    
    warning_msg = (
        f"‚ö†Ô∏è Python {version.major}.{version.minor} ƒë∆∞·ª£c ph√°t hi·ªán. "
        f"Streamlit Cloud khuy·∫øn ngh·ªã Python 3.9-3.10. "
        f"Python 3.11+ ho·∫∑c 3.8- c√≥ th·ªÉ g√¢y l·ªói v·ªõi Whisper/PhoWhisper."
    )
    return False, warning_msg

# Check Python version early
_python_version_valid, _python_version_warning = check_python_version()
if _python_version_warning:
    try:
        import streamlit as st
        st.warning(_python_version_warning)
    except:
        print(_python_version_warning)

@st.cache_resource
def load_whisper_model(model_size="base"):
    """Load Whisper model v·ªõi cache"""
    try:
        # On Streamlit Cloud, force CPU even if CUDA is detected
        if os.getenv("STREAMLIT_SHARING", "").lower() == "true" or os.getenv("STREAMLIT_SERVER_BASE_URL", ""):
            device = "cpu"  # Force CPU on Cloud
        else:
            device = "cuda" if torch.cuda.is_available() else "cpu"
        
        model = whisper.load_model(model_size, device=device)
        return model, device
    except KeyError as ke:
        # Handle "missing field" errors
        error_msg = f"Missing field error: {str(ke)}"
        st.error(f"‚ùå L·ªói 'missing field' khi load Whisper model. ƒê√¢y th∆∞·ªùng do cache model b·ªã l·ªói.")
        st.warning("""
        **Kh·∫Øc ph·ª•c:**
        1. X√≥a cache Whisper: `rm -rf ~/.cache/whisper` (Linux) ho·∫∑c x√≥a th∆∞ m·ª•c cache tr√™n Windows
        2. Restart ·ª©ng d·ª•ng v√† th·ª≠ l·∫°i
        """)
        return None, None
    except RuntimeError as re:
        # Handle CUDA unavailable errors
        error_msg = str(re)
        if "cuda" in error_msg.lower() or "CUDA" in error_msg:
            st.error(f"‚ùå L·ªói CUDA: {error_msg}")
            st.info("üí° ƒêang t·ª± ƒë·ªông chuy·ªÉn sang CPU mode...")
            # Retry with CPU
            try:
                model = whisper.load_model(model_size, device="cpu")
                return model, "cpu"
            except Exception as cpu_err:
                st.error(f"‚ùå Kh√¥ng th·ªÉ load model ngay c·∫£ v·ªõi CPU: {str(cpu_err)}")
                return None, None
        else:
            raise  # Re-raise if not CUDA-related
    except Exception as e:
        error_msg = str(e)
        # Ki·ªÉm tra l·ªói network
        if "getaddrinfo failed" in error_msg or "urlopen error" in error_msg.lower():
            st.error(f"‚ùå L·ªói k·∫øt n·ªëi m·∫°ng khi t·∫£i Whisper model. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi internet ho·∫∑c th·ª≠ l·∫°i sau.")
            st.info("üí° Whisper c·∫ßn t·∫£i model t·ª´ internet l·∫ßn ƒë·∫ßu ti√™n. Model s·∫Ω ƒë∆∞·ª£c cache sau khi t·∫£i th√†nh c√¥ng.")
        else:
            st.error(f"L·ªói khi load Whisper model: {error_msg}")
        return None, None

def transcribe_audio(model, audio_path_or_array, sr=16000, language="vi", 
                     task="transcribe", verbose=False):
    """
    Transcribe audio s·ª≠ d·ª•ng Whisper
    
    Args:
        model: Whisper model
        audio_path_or_array: ƒê∆∞·ªùng d·∫´n file ho·∫∑c numpy array
        sr: Sample rate
        language: Ng√¥n ng·ªØ (vi cho ti·∫øng Vi·ªát)
        task: "transcribe" ho·∫∑c "translate"
        verbose: Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt
    """
    try:
        if model is None:
            return None
        
        # If audio_path_or_array is a filepath, preflight-check and create safe copy if needed
        audio_path_to_use = audio_path_or_array
        if isinstance(audio_path_or_array, str):
            # Retry a few times for transient file access issues
            for attempt in range(3):
                if os.path.exists(audio_path_to_use) and os.path.isfile(audio_path_to_use):
                    try:
                        with open(audio_path_to_use, 'rb'):
                            pass
                        break
                    except Exception:
                        time.sleep(0.1 * (attempt + 1))
                        continue
                else:
                    # Try to create a safe temp copy if original filename could be problematic
                    try:
                        tmp_copy = _make_safe_temp_copy(audio_path_to_use)
                        audio_path_to_use = tmp_copy
                        break
                    except Exception:
                        time.sleep(0.1 * (attempt + 1))
                        continue

        # Transcribe
        result = model.transcribe(
            audio_path_to_use,
            language=language,
            task=task,
            verbose=verbose,
            fp16=False  # S·ª≠ d·ª•ng fp32 ƒë·ªÉ tr√°nh l·ªói tr√™n CPU
        )

        return result
    except KeyError as ke:
        # Handle "missing field" errors during transcription
        error_msg = f"Missing field error during transcription: {str(ke)}"
        st.error(f"‚ùå L·ªói 'missing field' khi transcribe. ƒê√¢y th∆∞·ªùng do model cache b·ªã l·ªói.")
        st.warning("""
        **Kh·∫Øc ph·ª•c:**
        1. X√≥a cache Whisper: `rm -rf ~/.cache/whisper`
        2. Restart ·ª©ng d·ª•ng v√† th·ª≠ l·∫°i
        3. N·∫øu v·∫´n l·ªói, th·ª≠ model size nh·ªè h∆°n
        """)
        return None
    except Exception as e:
        error_msg = str(e)
        # Check for FFmpeg errors
        if "ffmpeg" in error_msg.lower() or "ffmpeg was not found" in error_msg.lower():
            st.error(f"‚ùå L·ªói FFmpeg khi transcribe: {error_msg}")
            st.warning("üí° ƒê·∫£m b·∫£o FFmpeg ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t v√† c·∫•u h√¨nh ƒë√∫ng.")
        else:
            st.error(f"L·ªói khi transcribe: {error_msg}")
        return None

def format_transcript(result: Dict, with_timestamps: bool = True) -> str:
    """Format transcript t·ª´ k·∫øt qu·∫£ Whisper"""
    if result is None:
        return ""
    
    text = result.get("text", "")
    segments = result.get("segments", [])
    
    if not with_timestamps or not segments:
        return text
    
    # Format v·ªõi timestamps
    formatted_lines = []
    for segment in segments:
        start = segment.get("start", 0)
        end = segment.get("end", 0)
        segment_text = segment.get("text", "").strip()
        
        if segment_text:
            formatted_lines.append(f"[{format_time(start)} - {format_time(end)}] {segment_text}")
    
    return "\n".join(formatted_lines)

def format_time(seconds: float) -> str:
    """Format th·ªùi gian t·ª´ seconds sang HH:MM:SS"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    
    if hours > 0:
        return f"{hours:02d}:{minutes:02d}:{secs:02d}.{millis:03d}"
    else:
        return f"{minutes:02d}:{secs:02d}.{millis:03d}"

def get_transcript_statistics(result: Dict, duration: float) -> Dict:
    """T√≠nh to√°n th·ªëng k√™ transcript"""
    if result is None:
        return {}
    
    text = result.get("text", "")
    words = text.split()
    
    return {
        'word_count': len(words),
        'character_count': len(text),
        'duration': duration,
        'words_per_minute': (len(words) / duration * 60) if duration > 0 else 0,
        'segments_count': len(result.get("segments", []))
    }

