"""
Settings / Advanced Page
C·∫•u h√¨nh n√¢ng cao cho technical users
"""
import streamlit as st
import os
import sys

# Add parent directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from app.components.layout import apply_custom_css
from core.utils.settings_manager import load_settings, save_settings, load_settings_from_file
from config import config

# Apply custom CSS
apply_custom_css()

# Page config
st.set_page_config(
    page_title="Settings - Vietnamese Speech to Text",
    page_icon="‚öôÔ∏è",
    layout="wide"
)

st.header("‚öôÔ∏è Settings & Advanced Configuration")

# Warning for non-technical users
st.warning("‚ö†Ô∏è Trang n√†y d√†nh cho ng∆∞·ªùi d√πng k·ªπ thu·∫≠t. Thay ƒë·ªïi settings c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn hi·ªáu su·∫•t v√† ƒë·ªô ch√≠nh x√°c.")

# Load current settings
current_settings = load_settings()

# Tabs
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ü§ñ Model Config", "‚ö° Inference", "üíæ Resource", 
    "üîß Pipeline", "üöÄ Deployment", "üêõ Debug"
])

with tab1:
    st.subheader("Model Configuration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        whisper_model_path = st.text_input(
            "Whisper Model Path",
            value=current_settings["model"]["whisper_model_path"],
            help="ƒê∆∞·ªùng d·∫´n ƒë·∫øn Whisper model (ƒë·ªÉ tr·ªëng ƒë·ªÉ d√πng default)"
        )
        
        phowhisper_repo = st.text_input(
            "PhoWhisper Repository",
            value=current_settings["model"]["phowhisper_repo"],
            help="HuggingFace repo cho PhoWhisper"
        )
    
    with col2:
        device = st.selectbox(
            "Device",
            ["cpu", "cuda"],
            index=0 if current_settings["model"]["device"] == "cpu" else 1,
            disabled=config.is_cloud(),
            help="CPU ho·∫∑c CUDA (t·ª± ƒë·ªông CPU tr√™n Cloud)"
        )
        
        precision = st.selectbox(
            "Precision",
            ["fp32", "fp16", "int8"],
            index=["fp32", "fp16", "int8"].index(current_settings["model"]["precision"]),
            help="Model precision (fp32 recommended)"
        )
    
    current_settings["model"]["whisper_model_path"] = whisper_model_path
    current_settings["model"]["phowhisper_repo"] = phowhisper_repo
    current_settings["model"]["device"] = device
    current_settings["model"]["precision"] = precision

with tab2:
    st.subheader("Inference Hyperparameters")
    
    col1, col2 = st.columns(2)
    
    with col1:
        beam_size = st.number_input(
            "Beam Size",
            min_value=1,
            max_value=20,
            value=current_settings["inference"]["beam_size"],
            help="S·ªë l∆∞·ª£ng beams cho beam search"
        )
        
        batch_size = st.number_input(
            "Batch Size",
            min_value=1,
            max_value=128,
            value=current_settings["inference"]["batch_size"],
            help="Batch size cho inference"
        )
    
    with col2:
        temperature = st.slider(
            "Temperature",
            min_value=0.0,
            max_value=2.0,
            value=current_settings["inference"]["temperature"],
            step=0.1,
            help="Temperature cho sampling (0.0 = greedy)"
        )
        
        best_of = st.number_input(
            "Best Of",
            min_value=1,
            max_value=20,
            value=current_settings["inference"]["best_of"],
            help="S·ªë l∆∞·ª£ng candidates ƒë·ªÉ ch·ªçn"
        )
    
    current_settings["inference"]["beam_size"] = beam_size
    current_settings["inference"]["batch_size"] = batch_size
    current_settings["inference"]["temperature"] = temperature
    current_settings["inference"]["best_of"] = best_of

with tab3:
    st.subheader("Resource & Performance Tuning")
    
    col1, col2 = st.columns(2)
    
    with col1:
        num_threads = st.number_input(
            "Number of Threads",
            min_value=1,
            max_value=16,
            value=current_settings["resource"]["num_threads"],
            help="S·ªë l∆∞·ª£ng threads cho CPU"
        )
        
        max_memory_mb = st.number_input(
            "Max Memory (MB)",
            min_value=512,
            max_value=16384,
            value=current_settings["resource"]["max_memory_mb"],
            step=512,
            help="Gi·ªõi h·∫°n memory usage"
        )
    
    with col2:
        quantization = st.selectbox(
            "Quantization",
            ["none", "int8", "int4"],
            index=["none", "int8", "int4"].index(current_settings["resource"]["quantization"]),
            help="Model quantization (gi·∫£m memory nh∆∞ng c√≥ th·ªÉ gi·∫£m accuracy)"
        )
    
    current_settings["resource"]["num_threads"] = num_threads
    current_settings["resource"]["max_memory_mb"] = max_memory_mb
    current_settings["resource"]["quantization"] = quantization

with tab4:
    st.subheader("Pipeline Configuration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        vad_enabled = st.checkbox(
            "Voice Activity Detection (VAD)",
            value=current_settings["pipeline"]["vad_enabled"],
            help="B·∫≠t VAD ƒë·ªÉ ph√°t hi·ªán speech segments"
        )
        
        diarization_backend = st.selectbox(
            "Diarization Backend",
            ["simple", "pyannote"],
            index=0 if current_settings["pipeline"]["diarization_backend"] == "simple" else 1,
            help="Backend cho speaker diarization"
        )
    
    with col2:
        max_speakers = st.number_input(
            "Max Speakers",
            min_value=1,
            max_value=10,
            value=current_settings["pipeline"]["max_speakers"],
            help="S·ªë l∆∞·ª£ng ng∆∞·ªùi n√≥i t·ªëi ƒëa"
        )
    
    current_settings["pipeline"]["vad_enabled"] = vad_enabled
    current_settings["pipeline"]["diarization_backend"] = diarization_backend
    current_settings["pipeline"]["max_speakers"] = max_speakers

with tab5:
    st.subheader("Deployment Configuration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        docker_image = st.text_input(
            "Docker Image",
            value=current_settings["deployment"]["docker_image"],
            help="Docker image name"
        )
        
        api_port = st.number_input(
            "API Port",
            min_value=1024,
            max_value=65535,
            value=current_settings["deployment"]["api_port"],
            help="Port cho FastAPI server"
        )
    
    with col2:
        cloud_run_url = st.text_input(
            "Cloud Run URL",
            value=current_settings["deployment"]["cloud_run"],
            help="Google Cloud Run deployment URL"
        )
        
        hf_spaces_url = st.text_input(
            "HuggingFace Spaces URL",
            value=current_settings["deployment"]["hf_spaces"],
            help="HuggingFace Spaces deployment URL"
        )
    
    current_settings["deployment"]["docker_image"] = docker_image
    current_settings["deployment"]["api_port"] = api_port
    current_settings["deployment"]["cloud_run"] = cloud_run_url
    current_settings["deployment"]["hf_spaces"] = hf_spaces_url

with tab6:
    st.subheader("Debug & Logging")
    
    col1, col2 = st.columns(2)
    
    with col1:
        log_level = st.selectbox(
            "Log Level",
            ["DEBUG", "INFO", "WARNING", "ERROR"],
            index=["DEBUG", "INFO", "WARNING", "ERROR"].index(current_settings["debug"]["log_level"]),
            help="Logging level"
        )
        
        enable_evaluation = st.checkbox(
            "Enable Evaluation",
            value=current_settings["debug"]["enable_evaluation"],
            help="B·∫≠t evaluation mode"
        )
    
    with col2:
        wer_cer_enabled = st.checkbox(
            "Calculate WER/CER",
            value=current_settings["debug"]["wer_cer_enabled"],
            help="T√≠nh Word Error Rate v√† Character Error Rate"
        )
    
    current_settings["debug"]["log_level"] = log_level
    current_settings["debug"]["enable_evaluation"] = enable_evaluation
    current_settings["debug"]["wer_cer_enabled"] = wer_cer_enabled

# Save/Load settings
st.markdown("---")
col1, col2, col3 = st.columns(3)

with col1:
    if st.button("üíæ Save Settings", type="primary", use_container_width=True):
        format_type = st.radio("Format", ["JSON", "YAML"], horizontal=True, key="save_format")
        if save_settings(current_settings, format=format_type.lower()):
            st.success(f"‚úÖ ƒê√£ l∆∞u settings v√†o settings.{format_type.lower()}")

with col2:
    uploaded_file = st.file_uploader("üìÅ Load Settings", type=["json", "yaml", "yml"], key="load_settings")
    if uploaded_file:
        file_content = uploaded_file.read().decode('utf-8')
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix=uploaded_file.name) as tmp:
            tmp.write(file_content)
            tmp_path = tmp.name
        
        loaded_settings = load_settings_from_file(tmp_path)
        if loaded_settings:
            st.success("‚úÖ ƒê√£ load settings!")
            st.json(loaded_settings)
            os.unlink(tmp_path)

with col3:
    if st.button("üîÑ Reset to Defaults", use_container_width=True):
        current_settings = load_settings()
        st.success("‚úÖ ƒê√£ reset v·ªÅ defaults!")
        st.rerun()

# Display current settings
with st.expander("üìã Current Settings (JSON)"):
    st.json(current_settings)

